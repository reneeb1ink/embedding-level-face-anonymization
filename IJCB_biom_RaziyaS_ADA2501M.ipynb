{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rk5KrPtygEQ7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Itn9Zl5Ji9Cu"
      },
      "outputs": [],
      "source": [
        "!unzip archive\\ \\(5\\).zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwzFqaj0jthl"
      },
      "outputs": [],
      "source": [
        "!ls lfw-deepfunneled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM76_yK2jx-Q"
      },
      "outputs": [],
      "source": [
        "!ls lfw-deepfunneled/lfw-deepfunneled | head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_NKXwd6j-QD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = \"lfw-deepfunneled/lfw-deepfunneled\"\n",
        "\n",
        "people = []\n",
        "counts = {}\n",
        "\n",
        "for person in os.listdir(DATA_DIR):\n",
        "    person_path = os.path.join(DATA_DIR, person)\n",
        "    if os.path.isdir(person_path):\n",
        "        images = os.listdir(person_path)\n",
        "        counts[person] = len(images)\n",
        "\n",
        "sorted_counts = sorted(counts.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_counts[:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 42\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "2dF4d0v1KfqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_8VnJFIkU9b"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"lfw-deepfunneled/lfw-deepfunneled\"\n",
        "\n",
        "N_IDENTITIES = 100\n",
        "IMAGES_PER_ID = 10\n",
        "\n",
        "eligible = [p for p, c in counts.items() if c >= IMAGES_PER_ID]\n",
        "print(\"Eligible identities:\", len(eligible))\n",
        "\n",
        "N_IDENTITIES_ACTUAL = min(N_IDENTITIES, len(eligible))\n",
        "chosen = random.sample(eligible, N_IDENTITIES_ACTUAL)\n",
        "print(\"Chosen identities:\", len(chosen))\n",
        "\n",
        "samples = []\n",
        "for person in chosen:\n",
        "    person_dir = os.path.join(DATA_DIR, person)\n",
        "    imgs = [f for f in os.listdir(person_dir) if f.lower().endswith(\".jpg\")]\n",
        "    picked = random.sample(imgs, IMAGES_PER_ID)\n",
        "    for fn in picked:\n",
        "        samples.append((os.path.join(person_dir, fn), person))\n",
        "\n",
        "print(\"Total samples:\", len(samples))\n",
        "samples[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4HIrp8IlV0J"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "IMG_SIZE = 160\n",
        "BLUR_K = (21, 21)\n",
        "\n",
        "def read_rgb(path, size=IMG_SIZE):\n",
        "    img = cv2.imread(path)\n",
        "    if img is None:\n",
        "        return None\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (size, size), interpolation=cv2.INTER_AREA)\n",
        "    return img\n",
        "\n",
        "def gaussian_blur(rgb, k=BLUR_K):\n",
        "    bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
        "    bgr = cv2.GaussianBlur(bgr, k, 0)\n",
        "    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYNy8qIOlY0A"
      },
      "outputs": [],
      "source": [
        "# 1 example for original vs blur\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "p0, person0 = samples[0]\n",
        "img0 = read_rgb(p0)\n",
        "img0b = gaussian_blur(img0)\n",
        "\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1); plt.imshow(img0); plt.title(\"Original\"); plt.axis(\"off\")\n",
        "plt.subplot(1,2,2); plt.imshow(img0b); plt.title(\"Blur\"); plt.axis(\"off\")\n",
        "plt.show()\n",
        "print(\"Identity:\", person0, \"| Path:\", p0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE1HZwEtlkSN"
      },
      "outputs": [],
      "source": [
        "!pip install insightface onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpnyihbDlwxn"
      },
      "outputs": [],
      "source": [
        "from insightface.app import FaceAnalysis\n",
        "\n",
        "app = FaceAnalysis(name='buffalo_l')\n",
        "app.prepare(ctx_id=0, det_size=(640, 640))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrfsBVLHl9Ul"
      },
      "outputs": [],
      "source": [
        "faces = app.get(img0)\n",
        "len(faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdwxMgX1mV9O"
      },
      "outputs": [],
      "source": [
        "def pick_main_face(faces):\n",
        "    areas = []\n",
        "    for f in faces:\n",
        "        x1, y1, x2, y2 = f.bbox\n",
        "        areas.append((x2 - x1) * (y2 - y1))\n",
        "    return faces[int(np.argmax(areas))]\n",
        "\n",
        "faces = app.get(img0)\n",
        "main_face = pick_main_face(faces)\n",
        "emb = main_face.embedding\n",
        "\n",
        "print(\"Detected faces:\", len(faces))\n",
        "print(\"Embedding shape:\", emb.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNJSk_GdmcyG"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "Z_orig = []\n",
        "Z_blur = []\n",
        "labels = []\n",
        "kept_paths = []   # ← ДОБАВИТЬ\n",
        "\n",
        "for path, person in tqdm(samples):\n",
        "\n",
        "    img = read_rgb(path)\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    # ORIGINAL\n",
        "    faces_orig = app.get(img)\n",
        "    if len(faces_orig) == 0:\n",
        "        continue\n",
        "    main_orig = pick_main_face(faces_orig)\n",
        "\n",
        "    # BLUR\n",
        "    img_blur = gaussian_blur(img)\n",
        "    faces_blur = app.get(img_blur)\n",
        "    if len(faces_blur) == 0:\n",
        "        continue\n",
        "    main_blur = pick_main_face(faces_blur)\n",
        "\n",
        "    Z_orig.append(main_orig.normed_embedding)\n",
        "    Z_blur.append(main_blur.normed_embedding)\n",
        "    labels.append(person)\n",
        "    kept_paths.append(path)   # ← ОБЯЗАТЕЛЬНО\n",
        "\n",
        "Z_orig = np.array(Z_orig)\n",
        "Z_blur = np.array(Z_blur)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Final shapes:\")\n",
        "print(\"Original:\", Z_orig.shape)\n",
        "print(\"Blur:\", Z_blur.shape)\n",
        "print(\"Labels:\", labels.shape)\n",
        "print(\"Kept paths:\", len(kept_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6ZmXiKZ6Br1"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "def pca_2d(Z):\n",
        "    Zs = StandardScaler(with_mean=True, with_std=True).fit_transform(Z)\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    Y = pca.fit_transform(Zs)\n",
        "    evr = pca.explained_variance_ratio_\n",
        "    return Y, evr\n",
        "\n",
        "Y_orig, evr_orig = pca_2d(Z_orig)\n",
        "Y_blur, evr_blur = pca_2d(Z_blur)\n",
        "\n",
        "print(\"Explained variance (2D) - Original:\", evr_orig, \"sum=\", evr_orig.sum())\n",
        "print(\"Explained variance (2D) - Blur:\", evr_blur, \"sum=\", evr_blur.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQBx7JiQ6cmU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_pca(Y, labels, title, n_ids=20):\n",
        "    uniq = np.unique(labels)\n",
        "    show = set(uniq[:n_ids])\n",
        "    mask = np.array([l in show for l in labels])\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.scatter(Y[mask, 0], Y[mask, 1], s=10)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.show()\n",
        "\n",
        "plot_pca(Y_orig, labels, \"PCA of ArcFace Embeddings (Original)\")\n",
        "plot_pca(Y_blur, labels, \"PCA of ArcFace Embeddings (Gaussian Blur)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OKsuFb-6gVy"
      },
      "outputs": [],
      "source": [
        "def separability_metrics(Y, labels):\n",
        "    ids = np.unique(labels)\n",
        "    centroids = {i: Y[labels==i].mean(axis=0) for i in ids}\n",
        "\n",
        "    intra = []\n",
        "    for i in ids:\n",
        "        Xi = Y[labels==i]\n",
        "        ci = centroids[i]\n",
        "        intra.append(np.mean(np.sum((Xi - ci)**2, axis=1)))\n",
        "    intra_var = float(np.mean(intra))\n",
        "\n",
        "    c = np.vstack([centroids[i] for i in ids])   # mean pairwise centroid dist\n",
        "    dists = []\n",
        "    for a in range(len(ids)):\n",
        "        for b in range(a+1, len(ids)):\n",
        "            dists.append(np.linalg.norm(c[a]-c[b]))\n",
        "    inter_centroid = float(np.mean(dists))\n",
        "\n",
        "    return intra_var, inter_centroid\n",
        "\n",
        "intra_o, inter_o = separability_metrics(Y_orig, labels)\n",
        "intra_b, inter_b = separability_metrics(Y_blur, labels)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"regime\": [\"original\", \"blur\"],\n",
        "    \"intra_var\": [intra_o, intra_b],\n",
        "    \"inter_centroid_dist\": [inter_o, inter_b],\n",
        "    \"evr2_sum\": [evr_orig.sum(), evr_blur.sum()]\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ1gqWpz9WVZ"
      },
      "source": [
        "Face Swapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxjX9N_r9Y5T"
      },
      "outputs": [],
      "source": [
        "!pip -q install huggingface_hub\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "import os\n",
        "\n",
        "os.makedirs(\"/root/.insightface/models\", exist_ok=True)\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"Aitrepreneur/insightface\",\n",
        "    filename=\"inswapper_128.onnx\",\n",
        "    local_dir=\"/root/.insightface/models\",\n",
        "    local_dir_use_symlinks=False\n",
        ")\n",
        "\n",
        "print(\"Downloaded to:\", model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8aSqQsv-URU"
      },
      "outputs": [],
      "source": [
        "from insightface.model_zoo import get_model\n",
        "\n",
        "swapper = get_model(\"/root/.insightface/models/inswapper_128.onnx\", download=False)\n",
        "print(\"Swapper loaded:\", type(swapper))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9BsbOru_D0u"
      },
      "outputs": [],
      "source": [
        "import hashlib\n",
        "\n",
        "def deterministic_donor_id(target_id, other_ids, path, seed=SEED):\n",
        "    key = f\"{seed}|{target_id}|{path}\".encode(\"utf-8\")\n",
        "    h = int(hashlib.md5(key).hexdigest(), 16)\n",
        "    return other_ids[h % len(other_ids)]\n",
        "\n",
        "def gan_swap(img_rgb, donor_face_obj):\n",
        "    faces = app.get(img_rgb)\n",
        "    if len(faces) == 0:\n",
        "        return None\n",
        "    target_face = pick_main_face(faces)\n",
        "    swapped = swapper.get(img_rgb, target_face, donor_face_obj, paste_back=True)\n",
        "    return swapped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4_t1tGO_ZPH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "donor_face_by_id = {}\n",
        "\n",
        "for person in np.unique(labels):\n",
        "    # берём любое фото этого person из samples\n",
        "    person_paths = [p for (p, lab) in samples if lab == person]\n",
        "    if len(person_paths) == 0:\n",
        "        continue\n",
        "\n",
        "    # детерминированно выбираем 1 фото (чтобы не было random.choice)\n",
        "    person_paths_sorted = sorted(person_paths)\n",
        "    idx = int(hashlib.md5(f\"{SEED}|{person}\".encode()).hexdigest(), 16) % len(person_paths_sorted)\n",
        "    pth = person_paths_sorted[idx]\n",
        "\n",
        "    img = read_rgb(pth)\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    faces = app.get(img)\n",
        "    if len(faces) == 0:\n",
        "        continue\n",
        "\n",
        "    donor_face_by_id[person] = pick_main_face(faces)\n",
        "\n",
        "print(\"Donor faces computed:\", len(donor_face_by_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GeVWNbdAAIW"
      },
      "outputs": [],
      "source": [
        "Z_gan = []\n",
        "labels_gan = []\n",
        "kept_paths_gan = []\n",
        "\n",
        "valid_ids = list(donor_face_by_id.keys())\n",
        "valid_set = set(valid_ids)\n",
        "\n",
        "for path, person in tqdm(zip(kept_paths, labels), total=len(labels)):\n",
        "    if person not in valid_set:\n",
        "        continue\n",
        "\n",
        "    img = read_rgb(path)\n",
        "    if img is None:\n",
        "        continue\n",
        "\n",
        "    other_ids = [i for i in valid_ids if i != person]\n",
        "    if len(other_ids) == 0:\n",
        "        continue\n",
        "\n",
        "    donor_id = deterministic_donor_id(person, other_ids, path, seed=SEED)\n",
        "    donor_face = donor_face_by_id[donor_id]\n",
        "\n",
        "    swapped = gan_swap(img, donor_face)\n",
        "    if swapped is None:\n",
        "        continue\n",
        "\n",
        "    faces_swapped = app.get(swapped)\n",
        "    if len(faces_swapped) == 0:\n",
        "        continue\n",
        "\n",
        "    main_swapped = pick_main_face(faces_swapped)\n",
        "\n",
        "    # лучше normed_embedding\n",
        "    Z_gan.append(main_swapped.normed_embedding)\n",
        "    labels_gan.append(person)\n",
        "    kept_paths_gan.append(path)\n",
        "\n",
        "Z_gan = np.array(Z_gan)\n",
        "labels_gan = np.array(labels_gan)\n",
        "\n",
        "print(\"GAN embeddings shape:\", Z_gan.shape)\n",
        "print(\"GAN labels shape:\", labels_gan.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZgNKM9rADgI"
      },
      "outputs": [],
      "source": [
        "Y_gan, evr_gan = pca_2d(Z_gan)\n",
        "intra_g, inter_g = separability_metrics(Y_gan, labels_gan)\n",
        "\n",
        "print(\"Explained variance (2D) - GAN:\", evr_gan, \"sum=\", evr_gan.sum())\n",
        "print(\"Intra-class variance (GAN):\", intra_g)\n",
        "print(\"Inter-centroid distance (GAN):\", inter_g)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_two_pca_separate(Y_left, labels_left,\n",
        "                          Y_right, labels_right,\n",
        "                          title_left, title_right,\n",
        "                          n_ids=20,\n",
        "                          save_path=None):\n",
        "\n",
        "    ids = np.unique(labels_left)[:n_ids]\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "\n",
        "    for u in ids:\n",
        "        mask_left = labels_left == u\n",
        "        mask_right = labels_right == u\n",
        "\n",
        "        axes[0].scatter(Y_left[mask_left, 0],\n",
        "                        Y_left[mask_left, 1], s=12)\n",
        "\n",
        "        axes[1].scatter(Y_right[mask_right, 0],\n",
        "                        Y_right[mask_right, 1], s=12)\n",
        "\n",
        "    axes[0].set_title(title_left)\n",
        "    axes[1].set_title(title_right)\n",
        "\n",
        "    axes[0].set_xlabel(\"PC1\")\n",
        "    axes[0].set_ylabel(\"PC2\")\n",
        "    axes[1].set_xlabel(\"PC1\")\n",
        "    axes[1].set_ylabel(\"PC2\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if save_path is not None:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Q5s1lfe9Xdgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCX_lk0qB-Tg"
      },
      "outputs": [],
      "source": [
        "# matching original PCA points for GAN-survived samples\n",
        "path_to_Yorig = {p: y for p, y in zip(kept_paths, Y_orig)}\n",
        "Y_orig_for_gan = np.array([path_to_Yorig[p] for p in kept_paths_gan])\n",
        "\n",
        "plot_two_pca_separate(Y_orig_for_gan, labels_gan, Y_gan, labels_gan,\n",
        "                      \"Original\", \"GAN Swap\", n_ids=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I1jxbFCmsB0"
      },
      "outputs": [],
      "source": [
        "plot_two_pca_separate(Y_orig, labels,\n",
        "                      Y_blur, labels,\n",
        "                      \"Original\", \"Gaussian Blur\",\n",
        "                      n_ids=20,\n",
        "                      save_path=\"fig1_pca_orig_blur.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqeSgFAfnr3Y"
      },
      "outputs": [],
      "source": [
        "plot_two_pca_separate(Y_orig_for_gan, labels_gan,\n",
        "                      Y_gan, labels_gan,\n",
        "                      \"Original\", \"GAN Swap\",\n",
        "                      n_ids=20,\n",
        "                      save_path=\"fig2_pca_orig_gan.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFPl-GPaoOYw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "regimes = [\"Original\", \"Blur\", \"GAN\"]\n",
        "intra_vals = [intra_o, intra_b, intra_g]\n",
        "inter_vals = [inter_o, inter_b, inter_g]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "\n",
        "# Intra-class variance\n",
        "axes[0].bar(regimes, intra_vals)\n",
        "axes[0].set_title(\"Intra-class Variance\")\n",
        "axes[0].set_ylabel(\"Variance\")\n",
        "\n",
        "# Inter-centroid distance\n",
        "axes[1].bar(regimes, inter_vals)\n",
        "axes[1].set_title(\"Inter-centroid Distance\")\n",
        "axes[1].set_ylabel(\"Distance\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"fig3_metrics.png\", dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"Saved fig3_metrics.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}